{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')  # this is not needed for langchain?\n",
    "\n",
    "from glob import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_paths = glob(\"cogs/korean/data/level_1/*/listening_text.txt\")\n",
    "texts = []\n",
    "for audio in audio_paths:\n",
    "    with open(audio, encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "        texts.append(text)\n",
    "\n",
    "text = texts[10].replace(\"\\n\", \" \")\n",
    "text2 = re.sub(\"[\\[\\]\\(\\)\\{\\}1234567890.?!:]\", \"\", text)\n",
    "text2 = text.replace(\"Track\", \"\")\n",
    "text2 = text.strip()\n",
    "# words = text.split()\n",
    "# words\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Get base form of korean words in the text delimited by ```\n",
    "Count occurences for each of the base form words in the text.\n",
    "\n",
    "Display the output in this format, where each row represents one word: \n",
    "Word, Base Form, Count\\n\n",
    "\n",
    "If the base form is the same as the original word found in the text, leave the Base Form column blank.\n",
    "\n",
    "For example:\n",
    "Word: '재미있어요', Base Form: '재미있다',\n",
    "Word: '안녕하세요', Base Form: '안녕하다',\n",
    "Word: '아프다', Base Form: '',\n",
    "Word: '멋있다, Base Form: '',\n",
    "Word: '지금, Base Form: '',\n",
    "Word: '사과예요', Base Form: '사과'\n",
    "Word: '사과했어요', Base Form: '사과하다'\n",
    "Word: '죄송합니다, Base Form: '죄송하다',\n",
    "Word: '괜찮아요, Base Form: '괜찮다',\n",
    "Word: '감사합니다, Base Form: '감사하다',\n",
    "Word: '디자이너예요, Base Form: '디자이너',\n",
    "\n",
    "```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_completion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pmark\\Desktop\\Caroline-bot\\zzllm_word_extraction.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pmark/Desktop/Caroline-bot/zzllm_word_extraction.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m result \u001b[39m=\u001b[39m get_completion(prompt2)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pmark/Desktop/Caroline-bot/zzllm_word_extraction.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m result\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_completion' is not defined"
     ]
    }
   ],
   "source": [
    "result = get_completion(prompt2)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_completion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pmark\\Desktop\\Caroline-bot\\zzllm_word_extraction.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pmark/Desktop/Caroline-bot/zzllm_word_extraction.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m instruction \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGet me korean base form of these korean words. \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pmark/Desktop/Caroline-bot/zzllm_word_extraction.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m    Display the output in this format, where each row represents one word \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pmark/Desktop/Caroline-bot/zzllm_word_extraction.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m    Word, Base Form, Count: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pmark/Desktop/Caroline-bot/zzllm_word_extraction.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# result = get_completion(chatt)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pmark/Desktop/Caroline-bot/zzllm_word_extraction.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m result \u001b[39m=\u001b[39m get_completion(prompt)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pmark/Desktop/Caroline-bot/zzllm_word_extraction.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m result\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_completion' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "instruction = \"Get me korean base form of these korean words. \\\n",
    "    Display the output in this format, where each row represents one word \\\n",
    "    Word, Base Form, Count: \"\n",
    "# result = get_completion(chatt)\n",
    "result = get_completion(prompt)\n",
    "result.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "# result2 = get_completion(chatt)\n",
    "# result2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{1} 1. Track01 (1) 남: 안녕하세요? 여: 안녕하세요? (2) 남: 처음 뵙겠습니다. 여: 반갑습니다. (3) 남: 죄송합니다. 여: 괜찮아요. (4) 남: 감사합니다. 여: 아니에요.  2. Track02 (1) 남: 어느 나라 사람이에요? 여: 저는 한국 사람이에요. (2) 남: 어느 나라 사람이에요? 여: 저는 중국 사람이에요. (3) 남: 필리핀 사람이에요? 여: 네, 저는 필리핀 사람이에요. (4) 남: 영국 사람이에요? 여: 아니요. 저는 프랑스 사람이에요.  3. Track03 (1) 왕타오: 에바 씨, 회사원이에요?  에바: 네. 저는 회사원이에요. (2) 왕타오: 장웨이 씨, 미용사예요? 장웨이: 아니요. 저는 디자이너예요. (3) 리나: 제임스 씨, 영어 선생님이에요? 제임스: 아니요, 저는 요리사예요. (4) 리나: 로이 씨, 한국어 선생님이에요?  로이: 아니요, 저는 영어 선생님이에요.  {2} 1. Track04 제임스: 처음 뵙겠습니다. 저는 제임스예요. 리나: 안녕하세요? 저는 리나예요. 제임스: 어느 나라 사람이에요? 리나: 저는 일본 사람이에요. 간호사예요. 제임스 씨, 프랑스 사람이에요? 제임스: 아니요. 저는 미국 사람이에요. 리나: 회사원이에요? 제임스: 아니요, 저는 영어 선생님이에요.  2. Track05 남1: 처음 뵙겠습니다. 저는 왕타오예요. 여: 반갑습니다. 저는 칼비예요. 남2: 안녕하세요? 저는 황남이에요. 남1: 칼비 씨. 어느 나라 사람이에요? 여: 저는 필리핀 사람이에요. 황남 씨, 중국 사람이에요? 남2: 아니요. 저는 베트남 사람이에요. 왕타오 씨. 중국 사람이에요? 남1: 네. 저는 중국 사람이에요. 남2: 학생이에요? 남1: 네, 저는 유학생이에요. 칼비 씨. 가수예요? 여: 아니요, 저는 주부예요. 황남 씨, 요리사예요? 남2: 아니요. 저는 은행원이에요. ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pmark\\Desktop\\Caroline-bot\\zzllm_word_extraction.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pmark/Desktop/Caroline-bot/zzllm_word_extraction.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m result\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "result.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'customer_response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pmark\\Desktop\\Caroline-bot\\zzllm_word_extraction.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pmark/Desktop/Caroline-bot/zzllm_word_extraction.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m row_words \u001b[39m=\u001b[39m customer_response\u001b[39m.\u001b[39mcontent\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pmark/Desktop/Caroline-bot/zzllm_word_extraction.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkorean_words2.csv\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pmark/Desktop/Caroline-bot/zzllm_word_extraction.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m row_words:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'customer_response' is not defined"
     ]
    }
   ],
   "source": [
    "row_words = customer_response.content.split(\"\\n\")\n",
    "with open(\"korean_words2.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for row in row_words:\n",
    "        f.write(f\"{row}\\n\")\n",
    "\n",
    "# customer_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Word, Base Form, Count\\n안녕하세요, 안녕하다, 2\\n처음, , 1\\n뵙겠습니다, , 2\\n반갑습니다, , 1\\n죄송합니다, , 1\\n괜찮아요, , 1\\n감사합니다, , 1\\n어느, , 2\\n나라, , 2\\n사람이에요, , 4\\n한국, , 1\\n중국, , 2\\n필리핀, , 2\\n영국, , 1\\n프랑스, , 2\\n왕타오, , 2\\n에바, , 1\\n회사원이에요, , 2\\n장웨이, , 1\\n미용사예요, , 1\\n디자이너예요, , 1\\n리나, , 2\\n제임스, , 2\\n영어, , 2\\n선생님이에요, , 2\\n로이, , 1\\n한국어, , 1\\n제임스예요, , 1\\n리나예요, , 1\\n일본, , 1\\n간호사예요, , 1\\n미국, , 1\\n칼비예요, , 1\\n황남이에요, , 1\\n칼비, , 1\\n중국, , 1\\n베트남, , 1\\n왕타오, , 1\\n학생이에요, , 1\\n유학생이에요, , 1\\n가수예요, , 1\\n주부예요, , 1\\n요리사예요, , 1\\n은행원이에요, , 1', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "chat = ChatOpenAI(temperature=0.0)\n",
    "template_string = \"\"\"\n",
    "I want to extract all words from the following text for creating vocabulary list.\n",
    "\n",
    "Go over every single word in the text, find out what is the meaning of the word.\n",
    "If it has a meaning, find the word's korean base form. Base form does not include any honorifics,\n",
    "nor sentence ending particles. It must not have any particle attached to it.\n",
    "If the base form is the same as the original word found in the text, leave the base form blank.\n",
    "\n",
    "For example:\n",
    "Word: '재미있어요', Base Form: '재미있다',\n",
    "Word: '안녕하세요', Base Form: '안녕하다',\n",
    "Word: '아프다', Base Form: '',\n",
    "Word: '멋있다, Base Form: '',\n",
    "Word: '지금, Base Form: '',\n",
    "Word: '사과예요', Base Form: '사과'\n",
    "Word: '사과했어요', Base Form: '사과하다'\n",
    "\n",
    "Then count the original word occurences.\n",
    "```{text}```\n",
    "\n",
    "Display the output in this format, where each row represents one word: \n",
    "Word, Base Form, Count\\n\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "customer_messages = prompt_template.format_messages(\n",
    "    text=text1\n",
    ")\n",
    "customer_response = chat(customer_messages)\n",
    "customer_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents with tables\n",
    "from langchain.agents import create_csv_agent\n",
    "# from langchain.agents import create_pandas_dataframe_agent  # might be the same\n",
    "# from langchain.llms import OpenAI  # without llms\n",
    "\n",
    "# # LangChain agents\n",
    "# llm = OpenAI(temperature=0)\n",
    "agent = create_csv_agent(chat, verbose=True)\n",
    "# agent = create_pandas_dataframe_agent(llm, df, verbose=True)\n",
    "# prompt = \"Make the values more readable, store the result into 'listening.csv'\"\n",
    "agent.run(customer_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with tables\n",
    "import pandas as pd\n",
    "import utils\n",
    "\n",
    "# Getting csv + df\n",
    "_, ws_dfs = utils.get_worksheets(\"Korea - Vocabulary (raw)\", (\"listening occurences\",))\n",
    "ws_df = ws_dfs[0]\n",
    "ws_df.to_csv(\"in.csv\", index=False)\n",
    "csv_df = pd.read_csv('in.csv', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging occurences\n",
    "df = csv_df.reset_index()\n",
    "word_agg_f = lambda x: ' '.join(str(val) for val in x if pd.notnull(val))\n",
    "\n",
    "grouped_df = df.groupby(['Word']).agg(word_agg_f)\n",
    "grouped_df[\"index\"] = grouped_df[\"index\"].str.split().str[0].astype(int)\n",
    "sorted_df = grouped_df.sort_values(by='index')\n",
    "sorted_df = sorted_df.drop(['index'], axis=1)\n",
    "sorted_df.to_csv('listening.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents with tables\n",
    "from langchain.agents import create_csv_agent\n",
    "from langchain.agents import create_pandas_dataframe_agent  # might be the same\n",
    "from langchain.llms import OpenAI  # without llms\n",
    "\n",
    "# # LangChain agents\n",
    "# llm = OpenAI(temperature=0)\n",
    "# # agent = create_csv_agent(llm, filepath, verbose=True)\n",
    "# agent = create_pandas_dataframe_agent(llm, df, verbose=True)\n",
    "# prompt = \"Make the values more readable, store the result into 'listening.csv'\"\n",
    "# agent.run(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RetrievalQA (not for me for now)\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path=\"out.csv\", encoding=\"utf-8\")\n",
    "data = loader.load()\n",
    "index_creator = VectorstoreIndexCreator(vectorstore_cls=DocArrayInMemorySearch)  # without par gives error\n",
    "docsearch = index_creator.from_loaders([loader])\n",
    "chain = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=docsearch.vectorstore.as_retriever(), input_key=\"question\")\n",
    "\n",
    "def ask_question(query):\n",
    "    response = chain({\"question\": query})\n",
    "    return response['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Get me country with the highest GDP.\"\n",
    "query2 = \"Create 'out22.csv', where will be 3 countries with the biggest happiness index\"\n",
    "print(ask_question(query2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandasai library - not publicly common, use langchain instead\n",
    "from pandasai import PandasAI\n",
    "from pandasai.llm.openai import OpenAI\n",
    "\n",
    "# pandasai\n",
    "llm = OpenAI(api_token=\"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\")\n",
    "pandas_ai = PandasAI(llm, verbose=True)\n",
    "\n",
    "# pandas_ai.run(df, prompt=prompt)\n",
    "# where 10 Korean words have the lowest Rank. Put them into file columns: Korean, Rank, Book_English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
