{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')  # this is not needed for langchain?\n",
    "\n",
    "from glob import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_paths = glob(\"cogs/korean/data/level_1/*/listening_text.txt\")\n",
    "texts = []\n",
    "for audio in audio_paths:\n",
    "    with open(audio, encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "        texts.append(text)\n",
    "\n",
    "text = texts[10].replace(\"\\n\", \" \")\n",
    "text2 = re.sub(\"[\\[\\]\\(\\)\\{\\}1234567890.?!:]\", \"\", text)\n",
    "text2 = text.replace(\"Track\", \"\")\n",
    "text2 = text.strip()\n",
    "# words = text.split()\n",
    "# words\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Get base form of korean words in the text delimited by ```\n",
    "Count occurences for each of the base form words in the text.\n",
    "\n",
    "Display the output in this format, where each row represents one word: \n",
    "Word, Base Form, Count\\n\n",
    "\n",
    "If the base form is the same as the original word found in the text, leave the Base Form column blank.\n",
    "\n",
    "For example:\n",
    "Word: '재미있어요', Base Form: '재미있다',\n",
    "Word: '안녕하세요', Base Form: '안녕하다',\n",
    "Word: '아프다', Base Form: '',\n",
    "Word: '멋있다, Base Form: '',\n",
    "Word: '지금, Base Form: '',\n",
    "Word: '사과예요', Base Form: '사과'\n",
    "Word: '사과했어요', Base Form: '사과하다'\n",
    "Word: '죄송합니다, Base Form: '죄송하다',\n",
    "Word: '괜찮아요, Base Form: '괜찮다',\n",
    "Word: '감사합니다, Base Form: '감사하다',\n",
    "Word: '디자이너예요, Base Form: '디자이너',\n",
    "\n",
    "```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Track04\\n(1) 다리가 아프면 저기에서 조금 쉴까요? - 다리가 아프다, 저기에서, 조금, 쉴까요\\n(2) 추우면 이 옷을 입으세요. - 추우면, 이, 옷을, 입으세요\\n(3) 내일 날씨가 좋으면 빨래를 할 거예요. - 내일, 날씨가, 좋으면, 빨래를, 할, 거예요\\n(4) 쇼핑이 끝났으면 집에 갑시다. - 쇼핑이, 끝났으면, 집에, 갑시다\\n\\n2. Track05\\n(1) 여: 토요일에 시간이 있어요? 영화관에 가서 영화를 볼까요?\\n남: 미안하지만 토요일에는 바빠요. 일요일에 만날까요?\\n여: 네, 좋아요. - 토요일에, 시간이, 있어요, 영화관에, 가서, 영화를, 볼까요, 미안하지만, 바빠요, 일요일에, 만날까요, 네, 좋아요\\n(2) 여: 내일 저녁에 시간이 있어요? 요리를 해서 같이 먹고 싶어요.\\n남: 내일은 친구하고 약속이 있어요. 모레 먹을까요?\\n여: 네, 좋아요. - 내일, 저녁에, 시간이, 있어요, 요리를, 해서, 같이, 먹고, 싶어요, 내일은, 친구하고, 약속이, 있어요, 모레, 먹을까요, 네, 좋아요\\n(3) 여:'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = get_completion(prompt2)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Word: '안녕하세요', Base Form: '안녕하다', Count: 2\",\n",
       " \"Word: '반갑습니다', Base Form: '반갑다', Count: 1\",\n",
       " \"Word: '처음', Base Form: '', Count: 2\",\n",
       " \"Word: '뵙겠습니다', Base Form: '뵙다', Count: 2\",\n",
       " \"Word: '죄송합니다', Base Form: '죄송하다', Count: 1\",\n",
       " \"Word: '괜찮아요', Base Form: '괜찮다', Count: 1\",\n",
       " \"Word: '감사합니다', Base Form: '감사하다', Count: 1\",\n",
       " \"Word: '아니에요', Base Form: '아니다', Count: 1\",\n",
       " \"Word: '어느', Base Form: '', Count: 2\",\n",
       " \"Word: '나라', Base Form: '', Count: 4\",\n",
       " \"Word: '사람이에요', Base Form: '사람이다', Count: 4\",\n",
       " \"Word: '한국', Base Form: '', Count: 1\",\n",
       " \"Word: '중국', Base Form: '', Count: 2\",\n",
       " \"Word: '필리핀', Base Form: '', Count: 2\",\n",
       " \"Word: '영국', Base Form: '', Count: 1\",\n",
       " \"Word: '프랑스', Base Form: '', Count: 2\",\n",
       " \"Word: '왕타오', Base Form: '', Count: 2\",\n",
       " \"Word: '에바', Base Form: '', Count: 1\",\n",
       " \"Word: '회사원이에요', Base Form: '회사원이다', Count: 2\",\n",
       " \"Word: '장웨이', Base Form: '', Count: 1\",\n",
       " \"Word: '미용사예요', Base Form: '미용사이다', Count: 1\",\n",
       " \"Word: '리나', Base Form: '', Count: 2\",\n",
       " \"Word: '제임스', Base Form: '', Count: 2\",\n",
       " \"Word: '영어', Base Form: '', Count: 2\",\n",
       " \"Word: '선생님이에요', Base Form: '선생님이다', Count:\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "instruction = \"Get me korean base form of these korean words. \\\n",
    "    Display the output in this format, where each row represents one word \\\n",
    "    Word, Base Form, Count: \"\n",
    "# result = get_completion(chatt)\n",
    "result = get_completion(prompt)\n",
    "result.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Get base form and count occurrences for words in:\\n남1: 처음 뵙다. 저는 왕타오이다.\\n여: 반갑다. 저는 칼비이다.\\n남2: 안녕하세요? 저는 황남이다.\\n남1: 칼비 씨. 어느 나라 사람이다?\\n여: 저는 필리핀 사람이다. 황남 씨, 중국 사람이다?\\n남2: 아니요. 저는 베트남 사람이다. 왕타오 씨. 중국 사람이다?\\n남1: 네. 저는 중국 사람이다.\\n남2: 학생이다?\\n남1: 네, 저는 유학생이다. 칼비 씨. 가수이다?\\n여: 아니요, 저는 주부이다. 황남 씨, 요리사이다?\\n남2: 아니요. 저는 은행원이다.\\n\\nBase form and word count:\\n- 처음: 1\\n- 뵙다: 1\\n- 저: 6\\n- 왕타오: 2\\n- 반갑다: 1\\n- 칼비: 3\\n- 안녕하세요: 1\\n- 황남: 3\\n- 아니요: 2\\n- 어느: 1\\n- 나라: 1\\n- 사람: 4\\n- 저는: 4\\n- 필리핀: 1\\n- 중국: 4\\n- 베트남: 1\\n- 네: 2\\n- 유학생: 1\\n- 학생: 1\\n- 가수: 1\\n- 아니요: 1\\n- 주부: 1\\n- 요리사: 1\\n- 은행원: 1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "# result2 = get_completion(chatt)\n",
    "# result2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{1}',\n",
       " '1. Track04',\n",
       " '(1) 다리가 아프면 저기에서 조금 쉴까요?',\n",
       " '(2) 추우면 이 옷을 입으세요.',\n",
       " '(3) 내일 날씨가 좋으면 빨래를 할 거예요.',\n",
       " '(4) 쇼핑이 끝났으면 집에 갑시다.',\n",
       " '',\n",
       " '2. Track05',\n",
       " '(1) 여: 토요일에 시간이 있어요? 영화관에 가서 영화를 볼까요?',\n",
       " '남: 미안하지만 토요일에는 바빠요. 일요일에 만날까요?',\n",
       " '여: 네, 좋아요.',\n",
       " '(2) 여: 내일 저녁에 시간이 있어요? 요리를 해서 같이 먹고 싶어요.',\n",
       " '남: 내일은 친구하고 약속이 있어요. 모레 먹을까요?',\n",
       " '여: 네, 좋아요.',\n",
       " '(3) 여: 내일 바빠요? 공원에 가서 산책을 할까요?',\n",
       " '남: 내일 어머니께서 한국에 오세요. 다음 주에 할까요?',\n",
       " '여: 네, 좋아요.',\n",
       " '(4) 여: 커피를 마시고 싶어요.',\n",
       " '남: 그럼 같이 커피숍에 갈까요?',\n",
       " '여: 커피를 마시고 싶지만 날씨가 추워요. 밖에 안 나가고 싶어요.',\n",
       " '남: 그래요? 알겠어요. 그럼 저 혼자 갔다 올게요.',\n",
       " '']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Word: '다리가', Base Form: '다리'\",\n",
       " \"Word: '아프면', Base Form: '아프다'\",\n",
       " \"Word: '저기에서', Base Form: '저기'\",\n",
       " \"Word: '조금', Base Form: ''\",\n",
       " \"Word: '쉴까요', Base Form: '쉬다'\",\n",
       " \"Word: '추우면', Base Form: '춥다'\",\n",
       " \"Word: '이', Base Form: ''\",\n",
       " \"Word: '옷을', Base Form: '옷'\",\n",
       " \"Word: '입으세요', Base Form: '입다'\",\n",
       " \"Word: '내일', Base Form: ''\",\n",
       " \"Word: '날씨가', Base Form: '날씨'\",\n",
       " \"Word: '좋으면', Base Form: '좋다'\",\n",
       " \"Word: '빨래를', Base Form: '빨래'\",\n",
       " \"Word: '할', Base Form: ''\",\n",
       " \"Word: '거예요', Base Form: '거'\",\n",
       " \"Word: '쇼핑이', Base Form: '쇼핑'\",\n",
       " \"Word: '끝났으면', Base Form: '끝나다'\",\n",
       " \"Word: '집에', Base Form: '집'\",\n",
       " \"Word: '갑시다', Base Form: '가다'\",\n",
       " \"Word: '토요일에', Base Form: '토요일'\",\n",
       " \"Word: '시간이', Base Form: '시간'\",\n",
       " \"Word: '있어요', Base Form: '있다'\",\n",
       " \"Word: '영화관에', Base Form: '영화관'\",\n",
       " \"Word: '가서', Base Form: '가다'\",\n",
       " \"Word: '영화를', Base Form: '영화'\",\n",
       " \"Word: '볼까요', Base Form: '보다'\",\n",
       " \"Word: '미안하지만', Base Form: '미안하다'\",\n",
       " \"Word: '토요일에는', Base Form: '토요일'\",\n",
       " \"Word: '바빠요', Base Form: '바쁘다'\",\n",
       " \"Word: '일요일에', Base Form: '일요일'\",\n",
       " \"Word: '만날까요', Base Form: '만나다'\",\n",
       " \"Word: '내\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_words = customer_response.content.split(\"\\n\")\n",
    "with open(\"korean_words2.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for row in row_words:\n",
    "        f.write(f\"{row}\\n\")\n",
    "\n",
    "# customer_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Word, Base Form, Count\\n안녕하세요, 안녕하다, 2\\n처음, , 1\\n뵙겠습니다, , 2\\n반갑습니다, , 1\\n죄송합니다, , 1\\n괜찮아요, , 1\\n감사합니다, , 1\\n어느, , 2\\n나라, , 2\\n사람이에요, , 4\\n한국, , 1\\n중국, , 2\\n필리핀, , 2\\n영국, , 1\\n프랑스, , 2\\n왕타오, , 2\\n에바, , 1\\n회사원이에요, , 2\\n장웨이, , 1\\n미용사예요, , 1\\n디자이너예요, , 1\\n리나, , 2\\n제임스, , 2\\n영어, , 2\\n선생님이에요, , 2\\n로이, , 1\\n한국어, , 1\\n제임스예요, , 1\\n리나예요, , 1\\n일본, , 1\\n간호사예요, , 1\\n미국, , 1\\n칼비예요, , 1\\n황남이에요, , 1\\n칼비, , 1\\n중국, , 1\\n베트남, , 1\\n왕타오, , 1\\n학생이에요, , 1\\n유학생이에요, , 1\\n가수예요, , 1\\n주부예요, , 1\\n요리사예요, , 1\\n은행원이에요, , 1', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "chat = ChatOpenAI(temperature=0.0)\n",
    "template_string = \"\"\"\n",
    "I want to extract all words from the following text for creating vocabulary list.\n",
    "\n",
    "Go over every single word in the text, find out what is the meaning of the word.\n",
    "If it has a meaning, find the word's korean base form. Base form does not include any honorifics,\n",
    "nor sentence ending particles. It must not have any particle attached to it.\n",
    "If the base form is the same as the original word found in the text, leave the base form blank.\n",
    "\n",
    "For example:\n",
    "Word: '재미있어요', Base Form: '재미있다',\n",
    "Word: '안녕하세요', Base Form: '안녕하다',\n",
    "Word: '아프다', Base Form: '',\n",
    "Word: '멋있다, Base Form: '',\n",
    "Word: '지금, Base Form: '',\n",
    "Word: '사과예요', Base Form: '사과'\n",
    "Word: '사과했어요', Base Form: '사과하다'\n",
    "\n",
    "Then count the original word occurences.\n",
    "```{text}```\n",
    "\n",
    "Display the output in this format, where each row represents one word: \n",
    "Word, Base Form, Count\\n\n",
    "\"\"\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "customer_messages = prompt_template.format_messages(\n",
    "    text=text1\n",
    ")\n",
    "customer_response = chat(customer_messages)\n",
    "customer_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents with tables\n",
    "from langchain.agents import create_csv_agent\n",
    "# from langchain.agents import create_pandas_dataframe_agent  # might be the same\n",
    "# from langchain.llms import OpenAI  # without llms\n",
    "\n",
    "# # LangChain agents\n",
    "# llm = OpenAI(temperature=0)\n",
    "agent = create_csv_agent(chat, verbose=True)\n",
    "# agent = create_pandas_dataframe_agent(llm, df, verbose=True)\n",
    "# prompt = \"Make the values more readable, store the result into 'listening.csv'\"\n",
    "agent.run(customer_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with tables\n",
    "import pandas as pd\n",
    "import utils\n",
    "\n",
    "# Getting csv + df\n",
    "_, ws_dfs = utils.get_worksheets(\"Korea - Vocabulary (raw)\", (\"listening occurences\",))\n",
    "ws_df = ws_dfs[0]\n",
    "ws_df.to_csv(\"in.csv\", index=False)\n",
    "csv_df = pd.read_csv('in.csv', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging occurences\n",
    "df = csv_df.reset_index()\n",
    "word_agg_f = lambda x: ' '.join(str(val) for val in x if pd.notnull(val))\n",
    "\n",
    "grouped_df = df.groupby(['Word']).agg(word_agg_f)\n",
    "grouped_df[\"index\"] = grouped_df[\"index\"].str.split().str[0].astype(int)\n",
    "sorted_df = grouped_df.sort_values(by='index')\n",
    "sorted_df = sorted_df.drop(['index'], axis=1)\n",
    "sorted_df.to_csv('listening.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents with tables\n",
    "from langchain.agents import create_csv_agent\n",
    "from langchain.agents import create_pandas_dataframe_agent  # might be the same\n",
    "from langchain.llms import OpenAI  # without llms\n",
    "\n",
    "# # LangChain agents\n",
    "# llm = OpenAI(temperature=0)\n",
    "# # agent = create_csv_agent(llm, filepath, verbose=True)\n",
    "# agent = create_pandas_dataframe_agent(llm, df, verbose=True)\n",
    "# prompt = \"Make the values more readable, store the result into 'listening.csv'\"\n",
    "# agent.run(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RetrievalQA (not for me for now)\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path=\"out.csv\", encoding=\"utf-8\")\n",
    "data = loader.load()\n",
    "index_creator = VectorstoreIndexCreator(vectorstore_cls=DocArrayInMemorySearch)  # without par gives error\n",
    "docsearch = index_creator.from_loaders([loader])\n",
    "chain = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=docsearch.vectorstore.as_retriever(), input_key=\"question\")\n",
    "\n",
    "def ask_question(query):\n",
    "    response = chain({\"question\": query})\n",
    "    return response['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Get me country with the highest GDP.\"\n",
    "query2 = \"Create 'out22.csv', where will be 3 countries with the biggest happiness index\"\n",
    "print(ask_question(query2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandasai library - not publicly common, use langchain instead\n",
    "from pandasai import PandasAI\n",
    "from pandasai.llm.openai import OpenAI\n",
    "\n",
    "# pandasai\n",
    "llm = OpenAI(api_token=\"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\")\n",
    "pandas_ai = PandasAI(llm, verbose=True)\n",
    "\n",
    "# pandas_ai.run(df, prompt=prompt)\n",
    "# where 10 Korean words have the lowest Rank. Put them into file columns: Korean, Rank, Book_English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
